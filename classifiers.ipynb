{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifiers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6BIYuB53lKo"
      },
      "source": [
        "!pip install livelossplot --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aZW3ME5Xyar"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from livelossplot import PlotLosses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ov7s8D3a0U9",
        "outputId": "423c77d4-4413-4a16-f2ee-42a8cd867125"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQj-IGQaa1A0",
        "outputId": "86f70010-346d-48bc-c00f-8777a9dc5a03"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YPv3x_UbDHl"
      },
      "source": [
        "train_set = np.load('drive/MyDrive/EDVAM/train.npy')\n",
        "train_label = np.load('drive/MyDrive/EDVAM/train_label.npy')\n",
        "\n",
        "test_set = np.load('drive/MyDrive/EDVAM/test.npy')\n",
        "test_label = np.load('drive/MyDrive/EDVAM/test_label.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPQNFV9rbKpL",
        "outputId": "25ec9401-c80d-4178-b3f5-98ba9743f0ac"
      },
      "source": [
        "train_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(190830, 300, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLBFk5DVc-Wt"
      },
      "source": [
        "time_samples = [i for i in range(0, 150, 6)] + [i for i in range(150, 240, 5)] + \\\n",
        "               [i for i in range(240, 290, 2)] + [i for i in range(290, 300)]\n",
        "features = [i for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrfH-g2vfoBX"
      },
      "source": [
        "ds_train = torch.utils.data.TensorDataset(torch.Tensor(train_set[:, time_samples, :][:, :, features]),\\\n",
        "                                          torch.Tensor(train_label).type(torch.LongTensor))\n",
        "train_loader = torch.utils.data.DataLoader(ds_train, batch_size=128, shuffle=True)\n",
        "\n",
        "ds_test = torch.utils.data.TensorDataset(torch.Tensor(test_set[:, time_samples, :][:, :, features]),\\\n",
        "                                         torch.Tensor(test_label).type(torch.LongTensor))\n",
        "test_loader = torch.utils.data.DataLoader(ds_test, batch_size=128, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1TVW5x0JFJR"
      },
      "source": [
        "datasets = {'train': train_loader, 'val': test_loader}\n",
        "dataset_sizes = {'train': len(train_set), 'val': len(test_set)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oMDc7vfhFJt"
      },
      "source": [
        "class lstmNet(nn.Module):\n",
        "  def __init__(self, input_size=len(features)):\n",
        "    super().__init__()\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=20, num_layers=3, batch_first=True)\n",
        "    self.fc1 = nn.Linear(20, 12)\n",
        "        \n",
        "  def forward(self, x):\n",
        "    x_, (h_n, c_n) = self.lstm(x)\n",
        "    x_ = (x_[:, -1, :])\n",
        "    x_ = self.fc1(x_)\n",
        "    return x_\n",
        "\n",
        "class gruNet(nn.Module):\n",
        "  def __init__(self, input_size=len(features)):\n",
        "    super().__init__()\n",
        "    self.gru = nn.GRU(input_size=input_size, hidden_size=20, num_layers=3, batch_first=True)\n",
        "    self.fc1 = nn.Linear(20, 12)\n",
        "        \n",
        "  def forward(self, x):\n",
        "    x_, h_n = self.gru(x)\n",
        "    x_ = (x_[:, -1, :])\n",
        "    x_ = self.fc1(x_)\n",
        "    return x_\n",
        "  \n",
        "class convNet(nn.Module):\n",
        "  def __init__(self, input_shape=(len(time_samples), len(features)), hidden_size=64, num_layers=1):\n",
        "    super().__init__()\n",
        "    self.input_shape = input_shape\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Conv1d(self.input_shape[0], 64, 3),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.5),\n",
        "      nn.Conv1d(64, 64, 3),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.5),\n",
        "      nn.MaxPool1d(2),\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(192, 100),\n",
        "      nn.Dropout(0.5),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(100, 12),\n",
        "      # nn.Softmax()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj1sPUGnkVKP"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n",
        "  best_model_wts = model.state_dict()\n",
        "  best_acc = 0.0\n",
        "  best_epoch = 0\n",
        "\n",
        "  liveloss = PlotLosses()\n",
        "  model = model.to(device)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    logs = {}\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        scheduler.step()\n",
        "        model.train(True)\n",
        "      else:\n",
        "        model.train(False)\n",
        "    \n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      for inputs, labels in datasets[phase]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if phase == 'train':\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "        \n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.detach() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "      \n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
        "\n",
        "      prefix = 'val_' if phase == 'val' else ''\n",
        "\n",
        "      logs[prefix + 'log loss'] = epoch_loss.item()\n",
        "      logs[prefix + 'accuracy'] = epoch_acc.item()\n",
        "\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "          best_acc = epoch_acc\n",
        "          best_epoch = epoch\n",
        "          best_model_wts = model.state_dict()\n",
        "    \n",
        "    liveloss.update(logs)\n",
        "    liveloss.send()\n",
        "  \n",
        "  return best_model_wts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEv4KZ-r8JUr"
      },
      "source": [
        "model = convNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic0f4H8b8W1x"
      },
      "source": [
        "best_model = train_model(model, criterion, optimizer, scheduler, 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPiNMoIzq-8h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}